{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import access\n",
    "\n",
    "###############################################################################################\n",
    "#            CONVERTE O ARQUIVO PARA .CSV E SALVA EM OUTRA PASTA O ARQUIVO ORIGINAL           #\n",
    "###############################################################################################\n",
    "def xlsx_to_csv(input_file, output_file, processed_folder):\n",
    "    # Carregue o arquivo Excel usando pandas\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Salve o DataFrame como um arquivo CSV separado por ponto e vírgula\n",
    "    df.to_csv(output_file, index=False, sep=';')\n",
    "\n",
    "    print(f'O arquivo {input_file} foi convertido para {output_file}.')\n",
    "\n",
    "    # Mova o arquivo original para a pasta de processados com '_processado' no nome\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "\n",
    "    # Construa o caminho completo para o arquivo original na pasta de processados\n",
    "    processed_original_file_path = os.path.join(processed_folder, os.path.basename(input_file.replace('.xlsx', '_processado.xlsx')))\n",
    "\n",
    "    # Mova o arquivo original para a pasta de processados\n",
    "    os.rename(input_file, processed_original_file_path)\n",
    "\n",
    "    print(f'O arquivo original foi movido para a pasta {processed_folder}.')\n",
    "\n",
    "def convert_files_in_folder(folder_path, processed_folder):\n",
    "    # Liste todos os arquivos na pasta de origem\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "\n",
    "    for file in files:\n",
    "        # Construa o caminho completo para o arquivo de entrada\n",
    "        input_file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        # Construa o caminho completo para o arquivo de saída\n",
    "        output_file_path = os.path.join(folder_path, file.replace('.xlsx', '.csv'))\n",
    "\n",
    "        # Chame a função para realizar a conversão e mover o arquivo\n",
    "        xlsx_to_csv(input_file_path, output_file_path, processed_folder)\n",
    "\n",
    "###############################################################################################\n",
    "#                               CARGA DO ARQUIVO NA TRANSIENT                                 #\n",
    "###############################################################################################\n",
    "\n",
    "# Substitua com o caminho da sua pasta de origem e a pasta de processados\n",
    "source_folder = access.source_folder\n",
    "processed_folder = access.processed_folder\n",
    "\n",
    "# Chame a função para converter todos os arquivos na pasta de origem\n",
    "convert_files_in_folder(source_folder, processed_folder)\n",
    "\n",
    "# Caminho para a chave do IAM\n",
    "key_path = access.key_path\n",
    "\n",
    "# Carregar credenciais\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "\n",
    "def load_to_bigquery(data_frame, dataset_id, table_id, credentials):\n",
    "    # Inicializar cliente BigQuery\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # Criar referência para a tabela de destino\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Configurações do job de carregamento\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        skip_leading_rows=0,\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "    )\n",
    "\n",
    "    # Carregar dados na tabela\n",
    "    job = client.load_table_from_dataframe(data_frame, table_ref, job_config=job_config)\n",
    "    job.result()  # Aguardar término do job\n",
    "\n",
    "    print(f'Dados carregados na tabela {table_id} no BigQuery.')\n",
    "\n",
    "    # Imprimir informações sobre a carga\n",
    "  \n",
    "    print(f'Número de linhas carregadas: {len(data_frame)}')\n",
    "\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f'Arquivo {file_path} excluído.')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao excluir o arquivo {file_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "#                               CARGA DO ARQUIVO NA TRANSIENT                                 #\n",
    "###############################################################################################\n",
    "\n",
    "print('truncate transient - nova carga ')\n",
    "# Construir a instrução SQL CREATE OR REPLACE --> TRUNCATE STG  -- VERSÃO GRATIS NÃO DEIXA FAZER TRUNCATE \n",
    "sql_create_replace_transient = f\"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE transient.stg_base_vendas (\n",
    "    ID_MARCA INT64,\n",
    "    MARCA STRING,\n",
    "    ID_LINHA INT64,\n",
    "    LINHA STRING,\n",
    "    DATA_VENDA DATE,\n",
    "    QTD_VENDA INT64\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL CREATE OR REPLACE\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "query_job_create_replace_transient = client.query(sql_create_replace_transient)\n",
    "query_job_create_replace_transient.result()\n",
    "\n",
    "# Substitua com as informações do seu projeto, dataset e tabela no BigQuery\n",
    "dataset_id_transient = 'transient'\n",
    "table_id_transient = 'stg_base_vendas'\n",
    "\n",
    "# Iterar sobre os arquivos no diretório de origem\n",
    "files_transient = [f for f in os.listdir(source_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file in files_transient:\n",
    "    # Caminho completo para o arquivo de entrada\n",
    "    input_file_path = os.path.join(source_folder, file)\n",
    "\n",
    "    # Carregar dados para o BigQuery\n",
    "    df_transient = pd.read_csv(input_file_path, delimiter=';')\n",
    "    load_to_bigquery(df_transient, dataset_id_transient, table_id_transient, credentials)\n",
    "\n",
    "    # Excluir o arquivo do diretório\n",
    "    delete_file(input_file_path)\n",
    "\n",
    "###############################################################################################\n",
    "#                               CARGA DO ARQUIVO NA RAW                                       #\n",
    "###############################################################################################\n",
    "\n",
    "print('truncate raw - nova carga ')\n",
    "# Construir a instrução SQL CREATE OR REPLACE --> TRUNCATE STG  -- VERSÃO GRATIS NÃO DEIXA FAZER TRUNCATE \n",
    "sql_create_replace_raw = f\"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE raw_data.t_base_vendas (\n",
    "    ID_MARCA INT64,\n",
    "    MARCA STRING,\n",
    "    ID_LINHA INT64,\n",
    "    LINHA STRING,\n",
    "    DATA_VENDA DATE,\n",
    "    QTD_VENDA INT64\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL CREATE OR REPLACE\n",
    "query_job_create_replace_raw = client.query(sql_create_replace_raw)\n",
    "query_job_create_replace_raw.result()\n",
    "\n",
    "# Substitua com as informações do seu projeto, dataset e tabela no BigQuery\n",
    "dataset_id_raw = 'raw_data'\n",
    "table_id_raw = 't_base_vendas'\n",
    "\n",
    "# Construir a instrução SQL\n",
    "sql_query_base_vendas = f\"\"\"\n",
    "SELECT\n",
    "  ID_MARCA,\n",
    "  MARCA,\n",
    "  ID_LINHA,\n",
    "  LINHA,\n",
    "  DATE(DATA_VENDA) AS DATA_VENDA,\n",
    "  QTD_VENDA\n",
    "FROM  transient.stg_base_vendas;\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL e salvar os resultados em um DataFrame\n",
    "query_job_base_vendas = client.query(sql_query_base_vendas)\n",
    "df_result_base_vendas = query_job_base_vendas.to_dataframe()\n",
    "\n",
    "# Verificar se há dados para inserir\n",
    "if not df_result_base_vendas.empty:\n",
    "    # Imprimir o DataFrame com os resultados\n",
    "    print(\"Carregando df:\")\n",
    "    # Carregar dados no BigQuery\n",
    "    load_to_bigquery(df_result_base_vendas, dataset_id_raw, table_id_raw, credentials)\n",
    "else:\n",
    "    print(f'Nenhum novo dado para inserir na {dataset_id_raw}.{table_id_raw}')\n",
    "\n",
    "###############################################################################################\n",
    "#                               CARGA DO ARQUIVO NA TRUSTED                                  #\n",
    "###############################################################################################\n",
    "\n",
    "# Construir a instrução SQL CREATE OR REPLACE --> TRUNCATE STG  -- VERSÃO GRATIS NÃO DEIXA FAZER TRUNCATE \n",
    "sql_create_replace_trusted = f\"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE trusted.t_base_vendas_ano_mes (\n",
    "  ANO_MES STRING,\n",
    "  QTD_VENDA INT64\n",
    ");\n",
    "\n",
    "CREATE OR REPLACE TABLE trusted.t_base_vendas_marca_linha (\n",
    "  MARCA STRING,\n",
    "  LINHA STRING,\n",
    "  QTD_VENDA INT64\n",
    ");\n",
    "\n",
    "\n",
    "CREATE OR REPLACE TABLE trusted.t_base_vendas_marca_ano_mes (\n",
    "  ANO_MES STRING,\n",
    "  MARCA STRING,\n",
    "  QTD_VENDA INT64\n",
    ");\n",
    "\n",
    "\n",
    "CREATE OR REPLACE TABLE trusted.t_base_vendas_linha_ano_mes (\n",
    "  ANO_MES STRING,\n",
    "  LINHA STRING,\n",
    "  QTD_VENDA INT64\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL CREATE OR REPLACE\n",
    "query_job_create_replace_trusted = client.query(sql_create_replace_trusted)\n",
    "query_job_create_replace_trusted.result()\n",
    "\n",
    "# --a. Tabela 1: Consolidado de vendas por ano e mês;\n",
    "dataset_id_trusted_ano_mes = 'trusted'\n",
    "table_id_trusted_ano_mes = 't_base_vendas_ano_mes'\n",
    "\n",
    "# Construir a instrução SQL\n",
    "sql_query_mes_ano = f\"\"\"\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m', DATA_VENDA) AS ANO_MES\n",
    "  , SUM(QTD_VENDA) as QTD_VENDA\n",
    "FROM   raw_data.t_base_vendas\n",
    "GROUP BY  1\n",
    "ORDER BY 1  ;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL e salvar os resultados em um DataFrame\n",
    "query_job_trusted_ano_mes = client.query(sql_query_mes_ano)\n",
    "df_result_trusted_ano_mes = query_job_trusted_ano_mes.to_dataframe()\n",
    "\n",
    "# Verificar se há dados para inserir\n",
    "if not df_result_trusted_ano_mes.empty:\n",
    "    # Imprimir o DataFrame com os resultados\n",
    "    print(\"Tabela 1: Consolidado de vendas por ano e mês:\")\n",
    " \n",
    "    # Carregar dados no BigQuery\n",
    "    load_to_bigquery(df_result_trusted_ano_mes, dataset_id_trusted_ano_mes, table_id_trusted_ano_mes, credentials)\n",
    "\n",
    "else:\n",
    "    print(f\"Nenhum novo dado para inserir na {dataset_id_trusted_ano_mes}.{table_id_trusted_ano_mes}.\")\n",
    "\n",
    "#--b. Tabela 2: Consolidado de vendas por marca e linha;\n",
    "dataset_id_trusted_marca_linha = 'trusted'\n",
    "table_id_trusted_marca_linha = 't_base_vendas_marca_linha'\n",
    "\n",
    "# Construir a instrução SQL\n",
    "sql_query_marca_linha = f\"\"\"\n",
    "SELECT\n",
    "    MARCA\n",
    "  , LINHA\n",
    "  , SUM(QTD_VENDA) as QTD_VENDA\n",
    "FROM\n",
    "  raw_data.t_base_vendas\n",
    "  GROUP BY  1,2\n",
    "  ORDER BY 1;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL e salvar os resultados em um DataFrame\n",
    "query_job_trusted_marca_linha = client.query(sql_query_marca_linha)\n",
    "df_result_trusted_marca_linha = query_job_trusted_marca_linha.to_dataframe()\n",
    "\n",
    "# Verificar se há dados para inserir\n",
    "if not df_result_trusted_marca_linha.empty:\n",
    "    # Imprimir o DataFrame com os resultados\n",
    "    print(\"Tabela 2: Consolidado de vendas por marca e linha:\")\n",
    " \n",
    "    # Carregar dados no BigQuery\n",
    "    load_to_bigquery(df_result_trusted_marca_linha, dataset_id_trusted_marca_linha, table_id_trusted_marca_linha, credentials)\n",
    "\n",
    "else:\n",
    "    print(F\"Nenhum novo dado para inserir na {dataset_id_trusted_marca_linha}.{table_id_trusted_marca_linha}.\")\n",
    "\n",
    "# --c. Tabela 3: Consolidado de vendas por marca, ano e mês;\n",
    "dataset_id_trusted_marca_ano_mes = 'trusted'\n",
    "table_id_trusted_marca_ano_mes = 't_base_vendas_marca_ano_mes'\n",
    "\n",
    "# Construir a instrução SQL\n",
    "sql_query_marca_ano_mes = f\"\"\"\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m', DATA_VENDA) AS ANO_MES\n",
    "  , MARCA\n",
    "  , SUM(QTD_VENDA) as QTD_VENDA\n",
    "FROM   raw_data.t_base_vendas\n",
    "GROUP BY  1, 2\n",
    "ORDER BY 1, 2;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL e salvar os resultados em um DataFrame\n",
    "query_job_trusted_marca_ano_mes = client.query(sql_query_marca_ano_mes)\n",
    "df_result_trusted_marca_ano_mes = query_job_trusted_marca_ano_mes.to_dataframe()\n",
    "\n",
    "# Verificar se há dados para inserir\n",
    "if not df_result_trusted_marca_ano_mes.empty:\n",
    "    # Imprimir o DataFrame com os resultados\n",
    "    print(\"Tabela 3: Consolidado de vendas por marca, ano e mês:\")\n",
    " \n",
    "    # Carregar dados no BigQuery\n",
    "    load_to_bigquery(df_result_trusted_marca_ano_mes, dataset_id_trusted_marca_ano_mes, table_id_trusted_marca_ano_mes, credentials)\n",
    "\n",
    "else:\n",
    "    print(f\"Nenhum novo dado para inserir na {dataset_id_trusted_marca_ano_mes}.{table_id_trusted_marca_ano_mes}.\")\n",
    "\n",
    "# --d. Tabela 4: Consolidado de vendas por linha, ano e mês;\n",
    "dataset_id_trusted_linha_ano_mes = 'trusted'\n",
    "table_id_trusted_linha_ano_mes = 't_base_vendas_linha_ano_mes'\n",
    "\n",
    "# Construir a instrução SQL\n",
    "sql_query_linha_ano_mes = f\"\"\"\n",
    "SELECT\n",
    "    FORMAT_DATE('%Y-%m', DATA_VENDA) AS ANO_MES\n",
    "  , LINHA\n",
    "  , SUM(QTD_VENDA) as QTD_VENDA\n",
    "FROM   raw_data.t_base_vendas\n",
    "GROUP BY  1, 2\n",
    "ORDER BY 1, 2;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Executar a instrução SQL e salvar os resultados em um DataFrame\n",
    "query_job_trusted_linha_ano_mes = client.query(sql_query_linha_ano_mes)\n",
    "df_result_trusted_linha_ano_mes = query_job_trusted_linha_ano_mes.to_dataframe()\n",
    "\n",
    "# Verificar se há dados para inserir\n",
    "if not df_result_trusted_linha_ano_mes.empty:\n",
    "    # Imprimir o DataFrame com os resultados\n",
    "    print(\"Tabela 4: Consolidado de vendas por linha, ano e mês:\")\n",
    " \n",
    "    # Carregar dados no BigQuery\n",
    "    load_to_bigquery(df_result_trusted_linha_ano_mes, dataset_id_trusted_linha_ano_mes, table_id_trusted_linha_ano_mes, credentials)\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
