{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABELA STAGE CRIADA: STG_ARQ_SFC_HORA_VIVER_BI\n",
      "Arquivo funcional/psp/roche/base_sfc_horadeviver_29.01.2024.xlsx.xlsx processado e excluído do S3\n",
      "TABELA STAGE CRIADA: STG_ARQ_ENVIOS_HORA_VIVER_BI\n",
      "Arquivo funcional/psp/roche/envios_horadeviver_29.01.2024.xlsx.xlsx processado e excluído do S3\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import snowflake.connector as sf\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import unidecode\n",
    "import os\n",
    "import access\n",
    "\n",
    "def processar_arquivo_sfc(s3, bucket_name, prefix, arquivo_contem, tabela_snowflake, procedimento_armazenado):\n",
    "    # Lista de arquivos .xlsx para processar\n",
    "    arquivos_a_processar = []\n",
    "\n",
    "    # Listar objetos no S3\n",
    "    objects = s3.list_objects(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    # Verificar se há arquivos no S3\n",
    "    if 'Contents' not in objects or not objects['Contents']:\n",
    "        print(f'Nenhum arquivo encontrado no S3 com prefixo {prefix}')\n",
    "        return\n",
    "\n",
    "\n",
    "    # Iterar sobre os objetos encontrados\n",
    "    for obj in objects.get('Contents', []):\n",
    "        key = obj[\"Key\"]\n",
    "        # Verificar se é um arquivo .xlsx e contém o nome específico\n",
    "        if key.endswith('.xlsx') and arquivo_contem in key:\n",
    "            arquivos_a_processar.append(key)\n",
    "\n",
    "    # Verificar se há arquivos a serem processados\n",
    "    if not arquivos_a_processar:\n",
    "        print(f'Nenhum arquivo encontrado no S3 com prefixo {prefix} e contendo {arquivo_contem}')\n",
    "        return        \n",
    "\n",
    "    # Processar cada arquivo .xlsx\n",
    "    for key in arquivos_a_processar:\n",
    "        try:\n",
    "            # Ler o arquivo .xlsx usando pandas\n",
    "            response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "            excel_data = pd.read_excel(BytesIO(response['Body'].read()), engine='openpyxl')\n",
    "\n",
    "            # Remover espaços, caracteres especiais, acentos e converter para maiúsculas nos nomes das colunas\n",
    "            excel_data.columns = [unidecode.unidecode(col).upper().replace(\" \", \"_\").replace(\".\", \"_\").replace(\"-\", \"_\").replace(\":\", \"\") for col in excel_data.columns]\n",
    "\n",
    "            # Adicionar a coluna NOME_ARQUIVO com o nome do arquivo\n",
    "            excel_data['NOME_ARQUIVO'] = os.path.basename(key)\n",
    "\n",
    "            # Iterar sobre as colunas e converter para o formato de data desejado\n",
    "            for col in excel_data.columns:\n",
    "                if 'DATA' in col or 'PREVISAO' in col:  # Ajustar conforme necessário\n",
    "                    excel_data[col] = pd.to_datetime(excel_data[col], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Configuração do Snowflake\n",
    "            snowflake_connection = {\n",
    "                'account': access.ACCOUNT_SF,\n",
    "                'user': access.USER_SF,\n",
    "                'password': access.PWD_SF,\n",
    "                'warehouse': 'WHDEV',\n",
    "                'database': 'BCARE',\n",
    "                'schema': 'TRANSIENT',\n",
    "            }\n",
    "\n",
    "            # Configuração da conexão Snowflake\n",
    "            connSF = sf.connect(**snowflake_connection)\n",
    "            sfq = connSF.cursor()\n",
    "\n",
    "            # Montar a string para criar a tabela\n",
    "            columns_definition = ', '.join([f'{col} STRING' for col in excel_data.columns])\n",
    "\n",
    "            create_table = f\"\"\"\n",
    "            CREATE OR REPLACE TABLE BCARE.TRANSIENT.{tabela_snowflake} (\n",
    "            {columns_definition}\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "            sfq.execute(create_table)\n",
    "            #print(create_table)\n",
    "\n",
    "            print(f\"TABELA STAGE CRIADA: {tabela_snowflake}\")         \n",
    "\n",
    "            #print(excel_data)\n",
    "\n",
    "            # Carregar dados no Snowflake apenas se houver dados\n",
    "            if not excel_data.empty:\n",
    "                success, num_chunks, num_rows, output = write_pandas(\n",
    "                    conn=connSF,\n",
    "                    df=excel_data,\n",
    "                    table_name=tabela_snowflake,\n",
    "                    database='BCARE',\n",
    "                    schema='TRANSIENT',\n",
    "                )\n",
    "\n",
    "                # Executar procedimento armazenado apenas se houver sucesso no carregamento\n",
    "                if success:\n",
    "                    proc = f\"CALL BCARE.TRANSIENT.{procedimento_armazenado}();\"\n",
    "                    sfq.execute(\"USE WAREHOUSE WHDEV;\")\n",
    "                    sfq.execute(proc)\n",
    "\n",
    "                    print(f'Arquivo {key} processado e excluído do S3')\n",
    "                    # Excluir o arquivo .xlsx original do S3\n",
    "                    s3.delete_object(Bucket=bucket_name, Key=key)\n",
    "                else:\n",
    "                    print(f'Erro ao carregar dados do arquivo {key} no Snowflake')\n",
    "            else:\n",
    "                print(f'Nenhum dado para carregar do arquivo {key}')\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f'Erro ao processar o arquivo {key}: {err}')\n",
    "\n",
    "# Substitua 'seu_bucket' pelo nome do seu bucket S3\n",
    "#bucket_name = \"funcional-datalake-zone-landing\"\n",
    "\n",
    "# Crie uma instância do cliente S3\n",
    "s3 = boto3.client('s3', aws_access_key_id=access.aws_access_key_id,\n",
    "                  aws_secret_access_key=access.aws_secret_access_key)\n",
    "\n",
    "# Consulta para obter parâmetros\n",
    "query = \"\"\"\n",
    "SELECT BUCKET_NAME, PREFIX, ARQUIVO_CONTEM, TABELA_SNOWFLAKE, PROCEDIMENTO_ARMAZENADO  \n",
    "FROM MONITORAMENTO.PARAMETROS.CONFIG_ARQUIVOS_S3 \n",
    "WHERE ATIVO = 'YES';\n",
    "\"\"\"\n",
    "\n",
    "# Configuração do Snowflake para consulta\n",
    "snowflake_connection_query = {\n",
    "    'account': access.ACCOUNT_SF,\n",
    "    'user': access.USER_SF,\n",
    "    'password': access.PWD_SF,\n",
    "    'warehouse': 'WHDEV',\n",
    "    'database': 'MONITORAMENTO',\n",
    "    'schema': 'PARAMETROS',\n",
    "}\n",
    "\n",
    "# Conectar ao Snowflake\n",
    "connSF_query = sf.connect(**snowflake_connection_query)\n",
    "sfq_query = connSF_query.cursor()\n",
    "\n",
    "# Executar a consulta\n",
    "sfq_query.execute(query)\n",
    "results = sfq_query.fetchall()\n",
    "\n",
    "# Iterar sobre os resultados e chamar a função para cada conjunto de parâmetros\n",
    "for result in results:\n",
    "    processar_arquivo_sfc(\n",
    "        s3,\n",
    "        result[0],  # BUCKET_NAME\n",
    "        result[1],  # PREFIX\n",
    "        result[2],  # ARQUIVO_CONTEM\n",
    "        result[3],  # TABELA_SNOWFLAKE\n",
    "        result[4],  # PROCEDIMENTO_ARMAZENADO\n",
    "       \n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
